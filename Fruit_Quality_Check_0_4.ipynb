{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fruit_Quality_Check_0_4.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pradeepprasad/Machine_Learning_Workspace/blob/master/Fruit_Quality_Check_0_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKGVWXM5mGnS",
        "colab_type": "text"
      },
      "source": [
        "# **Model has been trained via Image_Pre_Processing_0_2 script with over 95 percent accuracy. Let's load model and test on some unseen uploaded images.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YA5-tEZm1Yz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "bdef768e-e6fb-469f-8e5b-17d17e2c651d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgdjZ6FknPAm",
        "colab_type": "text"
      },
      "source": [
        "Get some useful libraries and to ensure TF > 2 version is being used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NeCWev2leRe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e256d936-6eb3-45c4-b6ad-579e51d7678b"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pxPJGPyp41H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "outputId": "62580f40-195b-41f5-e7d4-ca6273809e03"
      },
      "source": [
        "# Recreate the exact same model, including its weights and the optimizer\n",
        "loaded_model = tf.keras.models.load_model('/content/drive/My Drive/model/fruit_quality_check_model_0003.hdf5')\n",
        "\n",
        "# Show the model architecture\n",
        "loaded_model.summary()\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 150, 150, 16)      448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 75, 75, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 75, 75, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 37, 37, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 37, 37, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 18, 18, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 20736)             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               10617344  \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 6)                 3078      \n",
            "=================================================================\n",
            "Total params: 10,644,006\n",
            "Trainable params: 10,644,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4x2NeR-Qq0nv",
        "colab_type": "text"
      },
      "source": [
        "Model is loaded and now time to see its accuracy. before that set test directory path."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGt_T9cgrbC2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b5bc5a1f-0455-4021-dddc-cce384bfb1ca"
      },
      "source": [
        "PATH = '/content/drive/My Drive/data/sample_data/dataset/dataset'\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'test')\n",
        "batch_size = 128\n",
        "epochs = 15\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150\n",
        "train_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our training data\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our validation data\n",
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='categorical')\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='categorical')\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 10901 images belonging to 6 classes.\n",
            "Found 2698 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dn8VWezqz7Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4694c95d-5041-4112-dd50-98c92d56f52b"
      },
      "source": [
        "loss, acc = loaded_model.evaluate(val_data_gen,verbose=2)\n",
        "print('Restored model, accuracy: {:5.2f}%'.format(100*acc))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22/22 - 822s - loss: 0.1191 - accuracy: 0.9533\n",
            "Restored model, accuracy: 95.33%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}