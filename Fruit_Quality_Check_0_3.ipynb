{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fruit_Quality_Check_0_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pradeepprasad/Machine_Learning_Workspace/blob/master/Fruit_Quality_Check_0_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsh83cfn6jB4",
        "colab_type": "text"
      },
      "source": [
        "Below are the pre-processing steps to download data files from Kaggle and moving in colab to specific folder for persistence across multiple session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGSmedskqh4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run this cell and select the kaggle.json file downloaded\n",
        "# from the Kaggle account settings page.\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCXcifiIvA-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Next, install the Kaggle API client.\n",
        "!pip install -q kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJalQaf7zUc_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls ../content/drive/'My Drive'/kaggle_login_file/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LKTJ0u3vGeH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The Kaggle API client expects this file to be in ~/.kaggle,\n",
        "# so move it there.\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp ../content/drive/'My Drive'/kaggle_login_file/kaggle.json ~/.kaggle/\n",
        "\n",
        "# This permissions change avoids a warning on Kaggle tool startup.\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLxcA67fvLuJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#list datasets\n",
        "!kaggle datasets list -s 'fruits'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1PgDsYa0T1S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd /content/drive/My Drive/data/sample_data/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpsoRur6vtvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle datasets download -d sriramr/fruits-fresh-and-rotten-for-classification "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrUXSgrU3gbP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle datasets download -d moltean/fruits "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5KTIiRDxorv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv fruits-fresh-and-rotten-for-classification.zip /content/sample_data/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQkTi3a5xz36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv kaggle.json /content/sample_data/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMqOvx7gyJPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls ../content/sample_data/fruits-fresh-and-rotten-for-classification.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLdrvBFv4yoA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip '/content/drive/My Drive/data/sample_data/fruits-fresh-and-rotten-for-classification.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCyiDkf85u2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv dataset /content/kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLNzisEi4JDD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls '/content/drive/My Drive/data/sample_data/dataset/train'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrxEYOE_7kyr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "d0c064ea-769e-4151-8bb0-77f63fd9c594"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fq7U-wY-64bF",
        "colab_type": "text"
      },
      "source": [
        "**Now we are proceeding to access the data available to us.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbqRR5CB54XP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e215ab30-e2d7-4394-ffd2-435674069f4c"
      },
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# TensorFlow ≥2.0-preview is required\n",
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "  print (\"tensorflow Version is \", tf.__version__)\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \"/content/drive/My Drive/temp\"\n",
        "PROJECT_ID = \"cnn/fruits_quality\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", PROJECT_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACRbItR59aH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_image(image):\n",
        "    plt.imshow(image, cmap=\"gray\", interpolation=\"nearest\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "def plot_color_image(image):\n",
        "    plt.imshow(image, interpolation=\"nearest\")\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoOHr9FuyvVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First, we are going to load the file names and their respective target labels into numpy array! \n",
        "from sklearn.datasets import load_files\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "\n",
        "#train_dir = '../input/fruits-360_dataset/fruits-360/Training'\n",
        "train_dir = '/content/drive/My Drive/data/sample_data/dataset/train'\n",
        "#test_dir = '../input/fruits-360_dataset/fruits-360/Test'\n",
        "test_dir = '/content/drive/My Drive/data/sample_data/dataset/test'\n",
        "\n",
        "def load_dataset_and_rescale(path):\n",
        "    img_datagen = ImageDataGenerator(\n",
        "                                    rescale = 1./255,\n",
        "                                    shear_range = 0.2,\n",
        "                                    zoom_range = 0.2,\n",
        "                                    horizontal_flip = True)\n",
        "    reszd_images = img_datagen.flow_from_directory(\n",
        "                                    path,\n",
        "                                    target_size = (100, 100),\n",
        "                                    batch_size = 100,\n",
        "                                    class_mode = 'categorical')\n",
        "    return reszd_images\n",
        "    \n",
        "train_set = load_dataset_and_rescale(train_dir)\n",
        "test_set = load_dataset_and_rescale(test_dir)\n",
        "print('Loading and scaling complete!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-aYnA6Hg8a3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now images are reshaped to 100*100,RGB format\n",
        "train_set.image_shape\n",
        "test_set.image_shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBzBw74D-Vsk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#now lets get how many classes we have.\n",
        "no_of_classes = train_set.num_classes\n",
        "no_of_classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPFdITN37WyG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#below gives total number of data in training set\n",
        "train_set.n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysOMxTMj9jMh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "61764a91-c260-42c4-bbd4-c467cbb81121"
      },
      "source": [
        "# lets plot some of images\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_sample_image\n",
        "\n",
        "# Load sample images\n",
        "fresh_apple = load_sample_image(\"/content/drive/My Drive/data/sample_data/dataset/train/freshapples/Screen Shot 2018-06-08 at 5.00.03 PM.png\") / 255\n",
        "rotten_apple = load_sample_image(\"/content/drive/My Drive/data/sample_data/dataset/train/rottenapples/Screen Shot 2018-06-07 at 2.16.18 PM.png\") / 255\n",
        "images = np.array([fresh_apple, rotten_apple])\n",
        "batch_size, height, width, channels = images.shape\n",
        "\n",
        "# Create 2 filters\n",
        "filters = np.zeros(shape=(7, 7, channels, 2), dtype=np.float32)\n",
        "filters[:, 3, :, 0] = 1  # vertical line\n",
        "filters[3, :, :, 1] = 1  # horizontal line\n",
        "\n",
        "outputs = tf.nn.conv2d(images, filters, strides=1, padding=\"SAME\")\n",
        "#outputs = tf.nn.conv2d(images, filters, strides=1, padding=\"VALID\")\n",
        "\n",
        "plt.imshow(outputs[0, :, :, 1], cmap=\"gray\") # plot 1st image's 2nd feature map\n",
        "plt.axis(\"off\") # Not shown in the book\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-89268693d62a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load sample images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfresh_apple\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_sample_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/data/sample_data/dataset/train/freshapples/Screen Shot 2018-06-08 at 5.00.03 PM.png\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mrotten_apple\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_sample_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/data/sample_data/dataset/train/rottenapples/Screen Shot 2018-06-07 at 2.16.18 PM.png\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfresh_apple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrotten_apple\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/datasets/base.py\u001b[0m in \u001b[0;36mload_sample_image\u001b[0;34m(image_name)\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot find sample image: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mimage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    846\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: Cannot find sample image: /content/drive/My Drive/data/sample_data/dataset/train/freshapples/Screen Shot 2018-06-08 at 5.00.03 PM.png"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHfRhjsJnTxa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Simple CNN from scratch - we are using 3 Conv layers followed by maxpooling layers.\n",
        "# At the end we add dropout, flatten and some fully connected layers(Dense).\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras.layers import Activation, Dense, Flatten, Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras import backend as K\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters = 16, kernel_size = 2,input_shape=(100,100,3),padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "\n",
        "model.add(Conv2D(filters = 32,kernel_size = 2,activation= 'relu',padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "\n",
        "model.add(Conv2D(filters = 64,kernel_size = 2,activation= 'relu',padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "\n",
        "model.add(Conv2D(filters = 128,kernel_size = 2,activation= 'relu',padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(150))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(no_of_classes,activation = 'softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8B4F-Uuq_O8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "print('Compiled!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJSZH_Syqe18",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Lets make model checkpoint directory\n",
        "!mkdir -p '/content/drive/My Drive/model'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE3CRxICBTrP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now train the model with checkpoint path\n",
        "batch_size = 32\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath = '/content/drive/My Drive/model/fruit_quality_check_model_0002.hdf5', verbose = 1, save_best_only = True)\n",
        "\n",
        "history = model.fit_generator(train_set,\n",
        "       # batch_size = 32,\n",
        "        epochs=30,\n",
        "        validation_data=(test_set),\n",
        "        callbacks = [checkpointer],\n",
        "        verbose=2, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJ4k0Bet8rJ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the weights that yielded the best validation accuracy\n",
        "model.load_weights('/content/drive/My Drive/model/fruit_quality_check_model_0002.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mot-ag0c8fdY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluate and print test accuracy\n",
        "score = model.evaluate(test_set, verbose=0)\n",
        "print('\\n', 'Test accuracy:', score[1])\n",
        "#98% accuracy !!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IeaVkRE9B1D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Finally lets visualize the loss and accuracy wrt epochs\n",
        "\n",
        "import matplotlib.pyplot as plt \n",
        "plt.figure(1)  \n",
        "   \n",
        " # summarize history for accuracy  \n",
        "   \n",
        "plt.subplot(211)  \n",
        "plt.plot(history.history['acc'])  \n",
        "plt.plot(history.history['val_acc'])  \n",
        "plt.title('model accuracy')  \n",
        "plt.ylabel('accuracy')  \n",
        "plt.xlabel('epoch')  \n",
        "plt.legend(['train', 'test'], loc='upper left')  \n",
        "   \n",
        " # summarize history for loss  \n",
        "   \n",
        "plt.subplot(212)  \n",
        "plt.plot(history.history['loss'])  \n",
        "plt.plot(history.history['val_loss'])  \n",
        "plt.title('model loss')  \n",
        "plt.ylabel('loss')  \n",
        "plt.xlabel('epoch')  \n",
        "plt.legend(['train', 'test'], loc='upper left')  \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdgNM3tV--iB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "size=100\n",
        "def predictFruitClass(ImagePath, trainedModel, class_dict):\n",
        "    \"\"\"\n",
        "    Perform class prediction on input image and print predicted class.\n",
        "\n",
        "    Args:\n",
        "        ImagePath(str): Absolute Path to test image\n",
        "        trainedModel(object): trained model from method getTrainedModel()\n",
        "        DictOfClasses(dict): python dict of all image classes.\n",
        "\n",
        "    Returns:\n",
        "        Probability of predictions for each class.\n",
        "    \"\"\"\n",
        "    x = image.load_img(ImagePath, target_size=(size,size))\n",
        "    x = image.img_to_array(x)\n",
        "    # for Display Only\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.imshow((x * 255).astype(np.uint8))\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    prediction_class = trainedModel.predict_classes(x, batch_size=1)\n",
        "    prediction_probs = trainedModel.predict_proba(x, batch_size=1)\n",
        "    print('probs:',prediction_probs)\n",
        "    print('class_index:',prediction_class[0])\n",
        "    for key, value in class_dict.items():\n",
        "        if value == prediction_class.item():\n",
        "            return key\n",
        "    return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7Avk2tY_v9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv '/content/class_dict.npy' '/content/drive/My Drive/model'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNcA8u2-AHUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_dict = np.load('/content/drive/My Drive/model/class_dict.npy', allow_pickle=True).item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bT8qu90G_CzJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_path = '/content/drive/My Drive/data/sample_data/dataset/test/rottenoranges/Screen Shot 2018-06-12 at 11.19.56 PM.png'\n",
        "single_pred = predictFruitClass(image_path,model, class_dict)\n",
        "print(single_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImN20oE9A8ty",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_path = '/content/drive/My Drive/data/sample_data/dataset/test/rottenbanana/Screen Shot 2018-06-12 at 8.51.00 PM.png'\n",
        "single_pred = predictFruitClass(image_path,model, class_dict)\n",
        "print(single_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNGUxsepBMYp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_path = '/content/drive/My Drive/data/sample_data/dataset/test/rottenbanana/Screen Shot 2018-06-12 at 8.58.57 PM.png'\n",
        "single_pred = predictFruitClass(image_path,model, class_dict)\n",
        "print(single_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWQ8Kg1FBXxe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_path = '/content/drive/My Drive/data/sample_data/dataset/test/freshapples/Screen Shot 2018-06-08 at 5.03.40 PM.png'\n",
        "single_pred = predictFruitClass(image_path,model, class_dict)\n",
        "print(single_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}